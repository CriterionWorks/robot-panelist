<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Voice Assistant</title>
    <style>
        body {
            margin: 0;
            padding: 0;
            background: linear-gradient(135deg, #1e3c72, #2a5298);
            font-family: 'Arial', sans-serif;
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            color: white;
        }

        .container {
            text-align: center;
            max-width: 800px;
            padding: 20px;
        }

        .face-container {
            position: relative;
            width: 300px;
            height: 300px;
            margin: 0 auto 30px;
            background: radial-gradient(circle, #4a90e2, #357abd);
            border-radius: 50%;
            box-shadow: 0 0 30px rgba(74, 144, 226, 0.5);
            display: flex;
            align-items: center;
            justify-content: center;
            transition: all 0.3s ease;
        }

        .face {
            position: relative;
            width: 200px;
            height: 200px;
        }

        .eyes {
            position: absolute;
            top: 60px;
            width: 100%;
            display: flex;
            justify-content: space-between;
            padding: 0 30px;
            box-sizing: border-box;
        }

        .eye {
            width: 25px;
            height: 25px;
            background: white;
            border-radius: 50%;
            position: relative;
            transition: all 0.2s ease;
        }

        .pupil {
            width: 12px;
            height: 12px;
            background: #333;
            border-radius: 50%;
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            transition: all 0.2s ease;
        }

        .mouth {
            position: absolute;
            bottom: 60px;
            left: 50%;
            transform: translateX(-50%);
            width: 60px;
            height: 30px;
            border: 3px solid white;
            border-top: none;
            border-radius: 0 0 60px 60px;
            transition: all 0.3s ease;
        }

        .mouth.talking {
            animation: talking 0.5s infinite alternate;
        }

        @keyframes talking {
            0% { height: 30px; }
            100% { height: 20px; }
        }

        .listening {
            animation: pulse 2s infinite;
        }

        @keyframes pulse {
            0%, 100% { transform: scale(1); box-shadow: 0 0 30px rgba(74, 144, 226, 0.5); }
            50% { transform: scale(1.05); box-shadow: 0 0 50px rgba(74, 144, 226, 0.8); }
        }

        .controls {
            margin: 20px 0;
        }

        .btn {
            background: #4CAF50;
            color: white;
            border: none;
            padding: 15px 30px;
            margin: 10px;
            border-radius: 25px;
            cursor: pointer;
            font-size: 16px;
            transition: all 0.3s ease;
            box-shadow: 0 4px 15px rgba(0, 0, 0, 0.2);
        }

        .btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(0, 0, 0, 0.3);
        }

        .btn.stop {
            background: #f44336;
        }

        .btn:disabled {
            background: #666;
            cursor: not-allowed;
            transform: none;
        }

        .status {
            margin: 20px 0;
            font-size: 18px;
            min-height: 60px;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .conversation {
            max-width: 600px;
            margin: 20px auto;
            text-align: left;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 15px;
            padding: 20px;
            max-height: 300px;
            overflow-y: auto;
        }

        .message {
            margin: 10px 0;
            padding: 10px;
            border-radius: 10px;
        }

        .user {
            background: rgba(76, 175, 80, 0.2);
            text-align: right;
        }

        .assistant {
            background: rgba(33, 150, 243, 0.2);
            text-align: left;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>AI Voice Assistant</h1>
        
        <div class="face-container" id="faceContainer">
            <div class="face">
                <div class="eyes">
                    <div class="eye">
                        <div class="pupil" id="leftPupil"></div>
                    </div>
                    <div class="eye">
                        <div class="pupil" id="rightPupil"></div>
                    </div>
                </div>
                <div class="mouth" id="mouth"></div>
            </div>
        </div>

        <div class="controls">
            <button class="btn" id="startBtn" onclick="startListening()">Start Listening</button>
            <button class="btn stop" id="stopBtn" onclick="stopListening()" disabled>Stop</button>
        </div>

        <div class="status" id="status">Ready to start</div>

        <div class="conversation" id="conversation"></div>
    </div>

    <script>
        let recognition;
        let isListening = false;
        let synth = window.speechSynthesis;
        let conversationHistory = [];
        
        // Debug logging
        const DEBUG = true;
        const debugLog = (message, data = null) => {
            if (DEBUG) {
                console.log(`[DEBUG] ${message}`, data || '');
            }
        };

        // Initialize speech recognition
        if ('webkitSpeechRecognition' in window) {
            recognition = new webkitSpeechRecognition();
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.lang = 'en-US';
        } else if ('SpeechRecognition' in window) {
            recognition = new SpeechRecognition();
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.lang = 'en-US';
        }

        // Test API connection on load
        async function testAPIConnection() {
            const connectionStatus = document.getElementById('connectionStatus');
            try {
                const apiKey = 'sk-ant-api03-your-new-key-here'; // Replace with your API key
                
                const response = await fetch('https://api.anthropic.com/v1/messages', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'x-api-key': apiKey,
                        'anthropic-version': '2023-06-01'
                    },
                    body: JSON.stringify({
                        model: 'claude-sonnet-4-20250514',
                        max_tokens: 10,
                        messages: [{ role: 'user', content: 'Hi' }]
                    })
                });

                if (response.ok) {
                    connectionStatus.textContent = '✅ Connected to Claude API';
                    connectionStatus.style.color = '#4CAF50';
                } else {
                    connectionStatus.textContent = '❌ API Connection Failed';
                    connectionStatus.style.color = '#f44336';
                }
            } catch (error) {
                connectionStatus.textContent = '❌ No Internet Connection';
                connectionStatus.style.color = '#f44336';
            }
        }

        // Test connection when page loads
        window.onload = testAPIConnection;

        function updateStatus(message) {
            document.getElementById('status').textContent = message;
        }

        function addToConversation(message, type) {
            const conversation = document.getElementById('conversation');
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${type}`;
            messageDiv.textContent = message;
            conversation.appendChild(messageDiv);
            conversation.scrollTop = conversation.scrollHeight;
        }

        function setFaceState(state) {
            const faceContainer = document.getElementById('faceContainer');
            const mouth = document.getElementById('mouth');
            
            faceContainer.classList.remove('listening');
            mouth.classList.remove('talking');
            
            if (state === 'listening') {
                faceContainer.classList.add('listening');
            } else if (state === 'talking') {
                mouth.classList.add('talking');
            }
        }

        function startListening() {
            debugLog('Starting listening function');
            
            if (!recognition) {
                debugLog('Speech recognition not supported');
                alert('Speech recognition not supported in this browser');
                return;
            }

            const apiKey = 'sk-ant-api03-your-new-key-here'; // Replace with your API key
            debugLog('API key configured');

            isListening = true;
            document.getElementById('startBtn').disabled = true;
            document.getElementById('stopBtn').disabled = false;
            
            setFaceState('listening');
            updateStatus('Listening...');

            recognition.onresult = function(event) {
                debugLog('Speech recognition result received');
                let finalTranscript = '';
                
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    if (event.results[i].isFinal) {
                        finalTranscript += event.results[i][0].transcript;
                    }
                }

                if (finalTranscript) {
                    debugLog('Final transcript:', finalTranscript);
                    processUserInput(finalTranscript.trim());
                }
            };

            recognition.onerror = function(event) {
                debugLog('Speech recognition error:', event.error);
                console.error('Speech recognition error:', event.error);
                updateStatus('Error: ' + event.error);
            };

            recognition.onend = function() {
                debugLog('Speech recognition ended, restarting if still listening');
                if (isListening) {
                    recognition.start(); // Restart if still listening
                }
            };

            recognition.start();
        }

        function stopListening() {
            isListening = false;
            if (recognition) {
                recognition.stop();
            }
            
            document.getElementById('startBtn').disabled = false;
            document.getElementById('stopBtn').disabled = true;
            
            setFaceState('idle');
            updateStatus('Stopped');
        }

        async function processUserInput(userText) {
            debugLog('Processing user input:', userText);
            
            if (userText.toLowerCase().includes('stop assistant')) {
                debugLog('Stop command detected');
                stopListening();
                return;
            }

            addToConversation(userText, 'user');
            updateStatus('Processing...');
            
            try {
                debugLog('Calling Anthropic API...');
                const response = await callAnthropicAPI(userText);
                debugLog('API response received:', response);
                addToConversation(response, 'assistant');
                speakResponse(response);
            } catch (error) {
                debugLog('API Error:', error);
                console.error('API Error:', error);
                updateStatus('Error: ' + error.message);
            }
        }

        async function callAnthropicAPI(message) {
            const apiKey = 'sk-ant-api03-your-new-key-here'; // Replace with your API key
            const systemPrompt = "You are a helpful AI assistant in a meeting. Keep responses concise and natural.";
            
            debugLog('Building conversation history...');
            conversationHistory.push({ role: 'user', content: message });
            
            const messages = [
                { role: 'system', content: systemPrompt },
                ...conversationHistory.slice(-10)
            ];
            
            debugLog('Sending API request with messages:', messages);

            const response = await fetch('https://api.anthropic.com/v1/messages', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'x-api-key': apiKey,
                    'anthropic-version': '2023-06-01'
                },
                body: JSON.stringify({
                    model: 'claude-sonnet-4-20250514',
                    max_tokens: 200,
                    messages: messages
                })
            });

            debugLog('API response status:', response.status);

            if (!response.ok) {
                const errorText = await response.text();
                debugLog('API error response:', errorText);
                throw new Error(`API Error: ${response.status} - ${errorText}`);
            }

            const data = await response.json();
            debugLog('API response data:', data);
            
            const assistantResponse = data.content[0].text;
            conversationHistory.push({ role: 'assistant', content: assistantResponse });
            
            return assistantResponse;
        }

        function speakResponse(text) {
            setFaceState('talking');
            updateStatus('Speaking...');
            
            const utterance = new SpeechSynthesisUtterance(text);
            utterance.rate = 0.9;
            utterance.pitch = 1;
            
            utterance.onend = function() {
                setFaceState('listening');
                updateStatus('Listening...');
            };
            
            synth.speak(utterance);
        }

        // Add some eye movement for life-like effect
        setInterval(() => {
            if (!isListening) return;
            
            const leftPupil = document.getElementById('leftPupil');
            const rightPupil = document.getElementById('rightPupil');
            
            const randomX = Math.random() * 6 - 3;
            const randomY = Math.random() * 6 - 3;
            
            leftPupil.style.transform = `translate(calc(-50% + ${randomX}px), calc(-50% + ${randomY}px))`;
            rightPupil.style.transform = `translate(calc(-50% + ${randomX}px), calc(-50% + ${randomY}px))`;
        }, 3000);
    </script>
</body>
</html>
